"""
æ—¶ç‚¹æŸ¥è¯¢æœåŠ¡
åŸºäºdebug_tool.pyè½¬æ¢è€Œæ¥ï¼Œæ”¯æŒç‰¹å®šæ—¶ç‚¹æŸ¥è¯¢å’Œå†å²è®°å½•ç®¡ç†
"""

import pandas as pd
from datetime import datetime
from typing import Dict, List, Any, Optional, Tuple
import json
import sys

from core.interfaces.tracker_interface import ITracker
from core.factories.tracker_factory import TrackerFactory
from utils.data_processor import DataProcessor
from utils.flow_integrity_validator import FlowIntegrityValidator
from utils.logger import audit_logger
from config import Config


class TimePointQueryService:
    """
    æ—¶ç‚¹æŸ¥è¯¢æœåŠ¡ - æŸ¥è¯¢ä»»æ„äº¤æ˜“è¡Œçš„ç³»ç»ŸçŠ¶æ€
    """
    
    def __init__(self, algorithm: str = "FIFO"):
        """
        åˆå§‹åŒ–æ—¶ç‚¹æŸ¥è¯¢æœåŠ¡
        
        Args:
            algorithm: ç®—æ³•ç±»å‹ ("FIFO" æˆ– "BALANCE_METHOD")
        """
        self.algorithm = algorithm
        self.tracker: Optional[ITracker] = None
        self.data_processor = DataProcessor()
        self.flow_validator = FlowIntegrityValidator()
        
        # æ•°æ®çŠ¶æ€
        self.data: Optional[pd.DataFrame] = None
        self.total_rows = 0
        self.current_row = 0
        
        # æŸ¥è¯¢å†å²ï¼ˆæœ€å¤šä¿å­˜100æ¡ï¼‰
        self.query_history: List[Dict[str, Any]] = []
        self.MAX_HISTORY_SIZE = 100
        
        # å¤„ç†è®°å½•
        self.processing_steps: List[Dict[str, Any]] = []
        self.error_records: List[Dict[str, Any]] = []
        
        audit_logger.info(f"æ—¶ç‚¹æŸ¥è¯¢æœåŠ¡åˆå§‹åŒ–å®Œæˆï¼Œä½¿ç”¨ç®—æ³•: {algorithm}")
    
    def load_data(self, file_path: str) -> Dict[str, Any]:
        """
        åŠ è½½Excelæ•°æ®æ–‡ä»¶
        
        Args:
            file_path: Excelæ–‡ä»¶è·¯å¾„
            
        Returns:
            åŠ è½½ç»“æœä¿¡æ¯
        """
        # åœ¨å‡½æ•°å¼€å§‹å°±å¯¼å…¥æ‰€éœ€çš„æ¨¡å—ï¼Œé¿å…ä½œç”¨åŸŸé—®é¢˜
        import logging
        from utils.logger import audit_logger
        
        try:
            audit_logger.info(f"å¼€å§‹åŠ è½½æ•°æ®æ–‡ä»¶: {file_path}")
            
            # 1. æ•°æ®é¢„å¤„ç†ï¼ˆé™é»˜æ¨¡å¼ï¼‰
            print("ğŸ“Š å¼€å§‹æ•°æ®é¢„å¤„ç†...", file=sys.stderr)
            sys.stderr.flush()
            sys.stdout.flush()
            
            # ä¸´æ—¶è°ƒæ•´æ—¥å¿—çº§åˆ«ï¼Œå‡å°‘è¯¦ç»†è¾“å‡º
            
            # ä¿å­˜åŸå§‹çº§åˆ«
            original_level = logging.getLogger().level
            original_audit_level = audit_logger.logger.level
            
            # è°ƒæ•´æ—¥å¿—çº§åˆ«ï¼šä¿ç•™é‡è¦ä¿¡æ¯ï¼ŒæŠ‘åˆ¶è¯¦ç»†çš„è´ªå¿ƒç®—æ³•æ­¥éª¤å’ŒWARNING
            logging.getLogger().setLevel(logging.ERROR)
            audit_logger.logger.setLevel(logging.ERROR)
            
            try:
                self.data = self.data_processor.é¢„å¤„ç†è´¢åŠ¡æ•°æ®(file_path)
            finally:
                # æ¢å¤åŸå§‹æ—¥å¿—çº§åˆ«
                logging.getLogger().setLevel(original_level)
                audit_logger.logger.setLevel(original_audit_level)
            
            if self.data is None:
                error_msg = "æ•°æ®é¢„å¤„ç†å¤±è´¥"
                audit_logger.error(error_msg)
                return {
                    "success": False,
                    "message": error_msg,
                    "file_path": file_path
                }
            print(f"âœ… æ•°æ®é¢„å¤„ç†å®Œæˆï¼Œå…±åŠ è½½ {len(self.data):,} æ¡è®°å½•", file=sys.stderr)
            sys.stderr.flush()
            sys.stdout.flush()
            
            # 2. æµæ°´å®Œæ•´æ€§éªŒè¯ï¼ˆé™é»˜æ¨¡å¼ï¼‰
            print("ğŸ” å¼€å§‹æµæ°´å®Œæ•´æ€§éªŒè¯...", file=sys.stderr)
            sys.stderr.flush()
            sys.stdout.flush()
            
            # ä¸´æ—¶æå‡æ—¥å¿—çº§åˆ«ä»¥å‡å°‘è¯¦ç»†è¾“å‡ºï¼ˆéšè—WARNINGä¿¡æ¯ï¼‰
            logging.getLogger().setLevel(logging.ERROR)
            audit_logger.logger.setLevel(logging.ERROR)
            
            try:
                validation_result = self.flow_validator.validate_flow_integrity(self.data)
            finally:
                # æ¢å¤åŸå§‹æ—¥å¿—çº§åˆ«
                logging.getLogger().setLevel(original_level)
                audit_logger.logger.setLevel(original_audit_level)
            if not validation_result['is_valid']:
                print(f"âš ï¸  æµæ°´å®Œæ•´æ€§éªŒè¯å‘ç° {validation_result['errors_count']} ä¸ªé—®é¢˜", file=sys.stderr)
                sys.stderr.flush()
                sys.stdout.flush()
                audit_logger.warning(f"æµæ°´å®Œæ•´æ€§éªŒè¯å‘ç°{validation_result['errors_count']}ä¸ªé—®é¢˜")
                
                if validation_result['optimization_failed']:
                    print("âŒ æµæ°´ä¼˜åŒ–å¤±è´¥ï¼Œæ— æ³•è‡ªåŠ¨ä¿®å¤æ•°æ®å®Œæ•´æ€§é—®é¢˜", file=sys.stderr)
                    sys.stderr.flush()
                    sys.stdout.flush()
                    audit_logger.error("âŒ æµæ°´ä¼˜åŒ–å¤±è´¥ï¼Œæ— æ³•è‡ªåŠ¨ä¿®å¤æ•°æ®å®Œæ•´æ€§é—®é¢˜")
                    return {
                        "success": False,
                        "message": "æµæ°´å®Œæ•´æ€§éªŒè¯å¤±è´¥ï¼Œæ— æ³•è‡ªåŠ¨ä¿®å¤",
                        "file_path": file_path
                    }
                
                if validation_result['optimizations_count'] > 0:
                    print(f"ğŸ”§ å·²é€šè¿‡é‡æ’åºä¿®å¤ {validation_result['optimizations_count']} ä¸ªé—®é¢˜", file=sys.stderr)
                    sys.stderr.flush()
                    sys.stdout.flush()
                    audit_logger.info(f"å·²é€šè¿‡é‡æ’åºä¿®å¤{validation_result['optimizations_count']}ä¸ªé—®é¢˜")
                    self.data = validation_result['result_dataframe']
                    print("âœ… ä½¿ç”¨ä¿®å¤åçš„æ•°æ®ç»§ç»­å¤„ç†ï¼ˆæºæ–‡ä»¶ä¿æŒä¸å˜ï¼‰", file=sys.stderr)
                    sys.stderr.flush()
                    sys.stdout.flush()
                    audit_logger.info("âœ… ä½¿ç”¨ä¿®å¤åçš„æ•°æ®ç»§ç»­å¤„ç†ï¼ˆæºæ–‡ä»¶ä¿æŒä¸å˜ï¼‰")
                    
                    # é‡è¦ï¼šæ•°æ®å·²é‡æ’åºï¼Œé‡ç½®DataFrameç´¢å¼•ä»¥é¿å…ä½™é¢éªŒè¯é—®é¢˜
                    self.data.reset_index(drop=True, inplace=True)
            else:
                print("âœ… æµæ°´å®Œæ•´æ€§éªŒè¯é€šè¿‡", file=sys.stderr)
                sys.stderr.flush()
                audit_logger.info("âœ… æµæ°´å®Œæ•´æ€§éªŒè¯é€šè¿‡")
                sys.stdout.flush()
                sys.stderr.flush()
            
            # 3. æ•°æ®éªŒè¯ï¼ˆé™é»˜æ¨¡å¼ï¼‰
            print("ğŸ” å¼€å§‹æ•°æ®éªŒè¯...", file=sys.stderr)
            sys.stderr.flush()
            sys.stdout.flush()
            
            # ä¸´æ—¶æå‡æ—¥å¿—çº§åˆ«ä»¥å‡å°‘è¯¦ç»†è¾“å‡ºï¼ˆéšè—WARNINGä¿¡æ¯ï¼‰
            logging.getLogger().setLevel(logging.ERROR)
            audit_logger.logger.setLevel(logging.ERROR)
            
            try:
                validation_result = self.data_processor.éªŒè¯æ•°æ®å®Œæ•´æ€§(self.data)
            finally:
                # æ¢å¤åŸå§‹æ—¥å¿—çº§åˆ«
                logging.getLogger().setLevel(original_level)
                audit_logger.logger.setLevel(original_audit_level)
            if not validation_result['is_valid']:
                print("âš ï¸  æ•°æ®éªŒè¯å‘ç°é—®é¢˜ï¼Œä½†ç»§ç»­å¤„ç†", file=sys.stderr)
                sys.stderr.flush()
                sys.stdout.flush()
                audit_logger.warning("æ•°æ®éªŒè¯å‘ç°é—®é¢˜ï¼Œä½†ç»§ç»­å¤„ç†")
                for error in validation_result['errors'][:5]:
                    audit_logger.warning(error)
            else:
                print("âœ… æ•°æ®éªŒè¯é€šè¿‡", file=sys.stderr)
                sys.stderr.flush()
                sys.stdout.flush()
                
            # 4. è®¾ç½®åŸºæœ¬ä¿¡æ¯
            self.total_rows = len(self.data)
            self.current_row = 0
            
            # æ¸…é™¤å†å²è®°å½•
            self.query_history.clear()
            self.processing_steps.clear()
            self.error_records.clear()
            
            result = {
                "success": True,
                "total_rows": self.total_rows,
                "message": f"æ•°æ®åŠ è½½æˆåŠŸï¼Œå…± {self.total_rows} è¡Œï¼ˆåŒ…å«å®Œæ•´æ€§éªŒè¯ï¼‰",
                "file_path": file_path
            }
            
            audit_logger.info(f"æ—¶ç‚¹æŸ¥è¯¢æ•°æ®åŠ è½½å®Œæˆ: {self.total_rows} è¡Œ")
            return result
                
        except Exception as e:
            error_msg = f"æ•°æ®åŠ è½½å‡ºé”™: {str(e)}"
            audit_logger.error(error_msg)
            return {
                "success": False,
                "message": error_msg,
                "error_details": str(e),
                "file_path": file_path
            }
    
    def query_time_point(self, target_row: int, save_to_history: bool = True) -> Dict[str, Any]:
        """
        æŸ¥è¯¢æŒ‡å®šæ—¶ç‚¹ï¼ˆè¡Œæ•°ï¼‰çš„ç³»ç»ŸçŠ¶æ€
        
        Args:
            target_row: ç›®æ ‡è¡Œæ•° (1-based)
            save_to_history: æ˜¯å¦ä¿å­˜åˆ°æŸ¥è¯¢å†å²
            
        Returns:
            æŸ¥è¯¢ç»“æœä¿¡æ¯
        """
        start_time = datetime.now()
        
        try:
            # è¾“å…¥éªŒè¯
            if self.data is None:
                return {
                    "success": False,
                    "message": "è¯·å…ˆåŠ è½½æ•°æ®æ–‡ä»¶",
                    "query_time": start_time.isoformat()
                }
            
            if target_row < 1 or target_row > self.total_rows:
                return {
                    "success": False,
                    "message": f"è¡Œæ•°è¶…å‡ºèŒƒå›´ (1-{self.total_rows})",
                    "query_time": start_time.isoformat()
                }
            
            audit_logger.info(f"å¼€å§‹æ—¶ç‚¹æŸ¥è¯¢: ç¬¬ {target_row} è¡Œï¼Œç®—æ³•: {self.algorithm}")
            
            # é‡ç½®è¿½è¸ªå™¨ï¼ˆæ¯æ¬¡æŸ¥è¯¢éƒ½ä»å¤´å¼€å§‹ï¼‰
            self._reset_tracker()
            
            # å¤„ç†æ•°æ®åˆ°ç›®æ ‡è¡Œ
            processing_result = self._process_to_row(target_row)
            
            if not processing_result["success"]:
                return {
                    "success": False,
                    "message": processing_result["message"],
                    "query_time": start_time.isoformat(),
                    "target_row": target_row
                }
            
            # ç”ŸæˆæŸ¥è¯¢ç»“æœ
            query_result = self._generate_query_result(target_row, start_time)
            
            # ä¿å­˜åˆ°å†å²è®°å½•
            if save_to_history:
                self._save_to_history(query_result)
            
            audit_logger.info(f"æ—¶ç‚¹æŸ¥è¯¢å®Œæˆ: ç¬¬ {target_row} è¡Œ")
            return query_result
            
        except Exception as e:
            error_msg = f"æ—¶ç‚¹æŸ¥è¯¢å¤±è´¥: {str(e)}"
            audit_logger.error(error_msg)
            return {
                "success": False,
                "message": error_msg,
                "error_details": str(e),
                "query_time": start_time.isoformat(),
                "target_row": target_row
            }
    
    def _reset_tracker(self) -> None:
        """é‡ç½®è¿½è¸ªå™¨çŠ¶æ€"""
        # é‡æ–°åˆ›å»ºè¿½è¸ªå™¨
        self.tracker = TrackerFactory.create_tracker(self.algorithm)
        self.current_row = 0
        self.processing_steps.clear()
        self.error_records.clear()
        
        # è®¾ç½®åˆå§‹ä½™é¢
        if self.data is not None:
            åˆå§‹ä½™é¢ = self.data_processor.è®¡ç®—åˆå§‹ä½™é¢(self.data)
            if åˆå§‹ä½™é¢ > 0:
                self.tracker.åˆå§‹åŒ–ä½™é¢(åˆå§‹ä½™é¢, 'å…¬å¸')
                
                self.processing_steps.append({
                    "step": 0,
                    "action": "åˆå§‹åŒ–ä½™é¢",
                    "amount": åˆå§‹ä½™é¢,
                    "result": f"åˆå§‹ä½™é¢è®¾ç½®ä¸º: {åˆå§‹ä½™é¢:,.2f} (å…¬å¸ä½™é¢)",
                    "timestamp": datetime.now()
                })
    
    def _process_to_row(self, target_row: int) -> Dict[str, Any]:
        """
        å¤„ç†æ•°æ®åˆ°æŒ‡å®šè¡Œæ•°
        
        Args:
            target_row: ç›®æ ‡è¡Œæ•°
            
        Returns:
            å¤„ç†ç»“æœ
        """
        try:
            import sys
            # é€è¡Œå¤„ç†åˆ°ç›®æ ‡è¡Œ
            progress_interval = max(1, target_row // 20)  # æœ€å¤šæ˜¾ç¤º20æ¬¡è¿›åº¦æ›´æ–°
            
            for i in range(target_row):
                try:
                    step_result = self._process_single_row(i)
                    if not step_result["success"]:
                        return {
                            "success": False,
                            "message": f"ç¬¬ {i + 1} è¡Œå¤„ç†å¤±è´¥: {step_result['message']}",
                            "failed_row": i + 1
                        }
                    
                    # æ˜¾ç¤ºè¿›åº¦ï¼ˆæ¯å¤„ç†ä¸€å®šæ•°é‡è¡Œå°±è¾“å‡ºä¸€æ¬¡ï¼‰
                    if (i + 1) % progress_interval == 0 or i + 1 == target_row:
                        percentage = (i + 1) / target_row * 100
                        print(f"â³ å¤„ç†è¿›åº¦: {i + 1}/{target_row} ({percentage:.1f}%)", file=sys.stderr)
                        sys.stderr.flush()
                    
                    # è·³è¿‡é€è¡Œä½™é¢éªŒè¯ï¼ˆæµæ°´å®Œæ•´æ€§éªŒè¯å·²ç¡®ä¿æ•°æ®æ­£ç¡®æ€§ï¼‰
                    # é¿å…ç”±äºæ•°æ®é‡æ’åºå¯¼è‡´çš„è¡Œå·ä¸åŒ¹é…é—®é¢˜
                
                except Exception as e:
                    error_info = {
                        'row': i + 1,
                        'error': str(e),
                        'timestamp': datetime.now(),
                        'tracker_state': self._get_tracker_state()
                    }
                    self.error_records.append(error_info)
                    
                    return {
                        "success": False,
                        "message": f"ç¬¬ {i + 1} è¡Œå¤„ç†å‡ºé”™: {str(e)}",
                        "failed_row": i + 1,
                        "error_details": str(e)
                    }
            
            self.current_row = target_row
            return {
                "success": True,
                "message": f"æˆåŠŸå¤„ç†åˆ°ç¬¬ {target_row} è¡Œ",
                "processed_rows": target_row
            }
            
        except Exception as e:
            return {
                "success": False,
                "message": f"æ‰¹é‡å¤„ç†å¤±è´¥: {str(e)}",
                "error_details": str(e)
            }
    
    def _process_single_row(self, row_idx: int) -> Dict[str, Any]:
        """
        å¤„ç†å•è¡Œæ•°æ®
        
        Args:
            row_idx: è¡Œç´¢å¼• (0-based)
            
        Returns:
            å¤„ç†ç»“æœ
        """
        try:
            row = self.data.iloc[row_idx]
            
            # ä½¿ç”¨æ•°æ®å¤„ç†å™¨å¤„ç†å•è¡Œäº¤æ˜“
            å¤„ç†ç»“æœ = self.data_processor.å¤„ç†å•è¡Œäº¤æ˜“(row, row_idx)
            
            # è®°å½•å¤„ç†æ­¥éª¤
            step_info = {
                "step": row_idx + 1,
                "action": "å¤„ç†äº¤æ˜“",
                "direction": å¤„ç†ç»“æœ['æ–¹å‘'],
                "amount": å¤„ç†ç»“æœ['å®é™…é‡‘é¢'],
                "fund_attr": å¤„ç†ç»“æœ['èµ„é‡‘å±æ€§'],
                "timestamp": datetime.now()
            }
            
            # æ ¹æ®äº¤æ˜“æ–¹å‘è°ƒç”¨è¿½è¸ªå™¨
            if å¤„ç†ç»“æœ['æ–¹å‘'] == 'æ”¶å…¥':
                if å¤„ç†ç»“æœ['is_investment']:
                    ä¸ªäººå æ¯”, å…¬å¸å æ¯”, è¡Œä¸ºæ€§è´¨ = self.tracker.å¤„ç†æŠ•èµ„äº§å“èµå›(
                        å¤„ç†ç»“æœ['å®é™…é‡‘é¢'], 
                        å¤„ç†ç»“æœ['èµ„é‡‘å±æ€§'], 
                        å¤„ç†ç»“æœ['å®Œæ•´æ—¶é—´æˆ³']
                    )
                else:
                    ä¸ªäººå æ¯”, å…¬å¸å æ¯”, è¡Œä¸ºæ€§è´¨ = self.tracker.å¤„ç†èµ„é‡‘æµå…¥(
                        å¤„ç†ç»“æœ['å®é™…é‡‘é¢'], 
                        å¤„ç†ç»“æœ['èµ„é‡‘å±æ€§'], 
                        å¤„ç†ç»“æœ['å®Œæ•´æ—¶é—´æˆ³']
                    )
            elif å¤„ç†ç»“æœ['æ–¹å‘'] == 'æ”¯å‡º':
                ä¸ªäººå æ¯”, å…¬å¸å æ¯”, è¡Œä¸ºæ€§è´¨ = self.tracker.å¤„ç†èµ„é‡‘æµå‡º(
                    å¤„ç†ç»“æœ['å®é™…é‡‘é¢'], 
                    å¤„ç†ç»“æœ['èµ„é‡‘å±æ€§'], 
                    å¤„ç†ç»“æœ['å®Œæ•´æ—¶é—´æˆ³']
                )
            else:
                ä¸ªäººå æ¯”, å…¬å¸å æ¯”, è¡Œä¸ºæ€§è´¨ = 0, 0, 'æ— äº¤æ˜“'
            
            # æ›´æ–°æ­¥éª¤ä¿¡æ¯
            step_info.update({
                "personal_ratio": ä¸ªäººå æ¯”,
                "company_ratio": å…¬å¸å æ¯”,
                "behavior": è¡Œä¸ºæ€§è´¨,
                "result": f"{å¤„ç†ç»“æœ['æ–¹å‘']} {å¤„ç†ç»“æœ['å®é™…é‡‘é¢']:,.2f} - {è¡Œä¸ºæ€§è´¨}"
            })
            
            self.processing_steps.append(step_info)
            
            # å°†è®¡ç®—å‡ºçš„è¡Œä¸ºæ€§è´¨å­˜å‚¨å›DataFrameä¸­ï¼Œä»¥ä¾¿æŸ¥è¯¢ç»“æœæ—¶ä½¿ç”¨
            if self.data is not None:
                self.data.at[row_idx, 'è¡Œä¸ºæ€§è´¨'] = è¡Œä¸ºæ€§è´¨
                self.data.at[row_idx, 'ä¸ªäººå æ¯”'] = ä¸ªäººå æ¯”
                self.data.at[row_idx, 'å…¬å¸å æ¯”'] = å…¬å¸å æ¯”
            
            return {
                "success": True,
                "message": f"ç¬¬ {row_idx + 1} è¡Œå¤„ç†æˆåŠŸ",
                "processing_result": å¤„ç†ç»“æœ,
                "personal_ratio": ä¸ªäººå æ¯”,
                "company_ratio": å…¬å¸å æ¯”,
                "behavior": è¡Œä¸ºæ€§è´¨
            }
            
        except Exception as e:
            return {
                "success": False,
                "message": f"ç¬¬ {row_idx + 1} è¡Œå¤„ç†å¤±è´¥: {str(e)}",
                "error_details": str(e)
            }
    
    def _validate_balance(self, row_num: int, expected_balance: float) -> bool:
        """
        éªŒè¯ä½™é¢æ˜¯å¦åŒ¹é…
        
        Args:
            row_num: è¡Œå· (1-based)
            expected_balance: æœŸæœ›ä½™é¢
            
        Returns:
            æ˜¯å¦åŒ¹é…
        """
        if self.tracker is None:
            return False
        
        actual_balance = self.tracker.ä¸ªäººä½™é¢ + self.tracker.å…¬å¸ä½™é¢
        
        # ä½¿ç”¨é…ç½®çš„å®¹å·®
        if abs(actual_balance - expected_balance) <= Config.BALANCE_TOLERANCE:
            return True
        else:
            # è®°å½•ä½™é¢é”™è¯¯
            error_info = {
                'row': row_num,
                'expected': expected_balance,
                'actual': actual_balance,
                'difference': actual_balance - expected_balance,
                'timestamp': datetime.now(),
                'tracker_state': self._get_tracker_state()
            }
            self.error_records.append(error_info)
            
            audit_logger.warning(f"ç¬¬{row_num}è¡Œä½™é¢ä¸åŒ¹é…: æœŸæœ›{expected_balance:,.2f}, å®é™…{actual_balance:,.2f}")
            return False
    
    def _get_tracker_state(self) -> Dict[str, Any]:
        """è·å–è¿½è¸ªå™¨å½“å‰çŠ¶æ€"""
        if self.tracker is None:
            return {}
        
        # è®¡ç®—èµ„é‡‘ç¼ºå£ï¼šç´¯è®¡æŒªç”¨ - ç´¯è®¡å½’è¿˜ç»™å…¬å¸çš„æœ¬é‡‘ - ç´¯è®¡å«ä»˜
        èµ„é‡‘ç¼ºå£ = (self.tracker.ç´¯è®¡æŒªç”¨é‡‘é¢ - 
                   self.tracker.ç´¯è®¡ç”±èµ„é‡‘æ± å›å½’å…¬å¸ä½™é¢æœ¬é‡‘ - 
                   self.tracker.ç´¯è®¡å«ä»˜é‡‘é¢)
        
        return {
            "personal_balance": self.tracker.ä¸ªäººä½™é¢,
            "company_balance": self.tracker.å…¬å¸ä½™é¢,
            "total_balance": self.tracker.ä¸ªäººä½™é¢ + self.tracker.å…¬å¸ä½™é¢,
            "total_misappropriation": self.tracker.ç´¯è®¡æŒªç”¨é‡‘é¢,  # ä¿®å¤å­—æ®µååŒ¹é…å‰ç«¯æœŸæœ›
            "total_advance": self.tracker.ç´¯è®¡å«ä»˜é‡‘é¢,
            "total_returned_company": self.tracker.ç´¯è®¡ç”±èµ„é‡‘æ± å›å½’å…¬å¸ä½™é¢æœ¬é‡‘,
            "total_returned_personal": self.tracker.ç´¯è®¡ç”±èµ„é‡‘æ± å›å½’ä¸ªäººä½™é¢æœ¬é‡‘,
            "personal_profit": self.tracker.æ€»è®¡ä¸ªäººåº”åˆ†é…åˆ©æ¶¦,
            "company_profit": self.tracker.æ€»è®¡å…¬å¸åº”åˆ†é…åˆ©æ¶¦,
            "funding_gap": èµ„é‡‘ç¼ºå£,       # ç»Ÿä¸€çš„èµ„é‡‘ç¼ºå£å­—æ®µ
            "is_initialized": self.tracker.å·²åˆå§‹åŒ–
        }
    
    def _generate_query_result(self, target_row: int, start_time: datetime) -> Dict[str, Any]:
        """
        ç”ŸæˆæŸ¥è¯¢ç»“æœ
        
        Args:
            target_row: ç›®æ ‡è¡Œæ•°
            start_time: æŸ¥è¯¢å¼€å§‹æ—¶é—´
            
        Returns:
            å®Œæ•´çš„æŸ¥è¯¢ç»“æœ
        """
        end_time = datetime.now()
        processing_time = (end_time - start_time).total_seconds()
        
        # åŸºæœ¬ä¿¡æ¯
        result = {
            "success": True,
            "algorithm": self.algorithm,
            "target_row": target_row,
            "total_rows": self.total_rows,
            "query_time": start_time.isoformat(),
            "processing_time": processing_time
        }
        
        # è¿½è¸ªå™¨çŠ¶æ€
        if self.tracker:
            result["tracker_state"] = self._get_tracker_state()
        
        # ç›®æ ‡è¡Œæ•°æ®
        if target_row > 0 and self.data is not None:
            import math
            target_row_data = self.data.iloc[target_row - 1]
            
            # å®‰å…¨è½¬æ¢æ•°å€¼ï¼Œå¤„ç†NaNå€¼
            def safe_float(value, default=0.0):
                try:
                    if value is None or (isinstance(value, float) and math.isnan(value)):
                        return default
                    return float(value)
                except (ValueError, TypeError):
                    return default
            
            # å¤„ç†èµ„é‡‘æµå‘ï¼šæ ¹æ®æ”¶å…¥æ”¯å‡ºé‡‘é¢åˆ¤æ–­
            income_amount = safe_float(target_row_data.get('äº¤æ˜“æ”¶å…¥é‡‘é¢'))
            expense_amount = safe_float(target_row_data.get('äº¤æ˜“æ”¯å‡ºé‡‘é¢'))
            
            if income_amount > 0 and expense_amount == 0:
                flow_type = "æ”¶å…¥"
            elif expense_amount > 0 and income_amount == 0:
                flow_type = "æ”¯å‡º"
            elif income_amount > 0 and expense_amount > 0:
                flow_type = "æ”¶æ”¯"
            else:
                flow_type = "æ— å˜åŠ¨"
            
            # å¤„ç†è¡Œä¸ºæ€§è´¨ï¼šæ¸…ç†æŠ•èµ„äº§å“çš„å‰ç¼€æ ¼å¼
            raw_behavior = str(target_row_data.get('è¡Œä¸ºæ€§è´¨', ''))
            clean_behavior = self._clean_behavior_description(raw_behavior)
            
            result["target_row_data"] = {
                "timestamp": str(target_row_data.get('å®Œæ•´æ—¶é—´æˆ³', '')),
                "income_amount": income_amount,
                "expense_amount": expense_amount,
                "balance": safe_float(target_row_data.get('ä½™é¢')),
                "fund_attr": str(target_row_data.get('èµ„é‡‘å±æ€§', '')),
                "flow_type": flow_type,
                "behavior": clean_behavior
            }
        
        # å¤„ç†ç»Ÿè®¡
        result["processing_stats"] = {
            "total_steps": len(self.processing_steps),
            "error_count": len(self.error_records),
            "last_processed_row": self.current_row
        }
        
        # æœ€è¿‘çš„å¤„ç†æ­¥éª¤ï¼ˆæœ€å¤š10æ­¥ï¼‰
        result["recent_steps"] = self.processing_steps[-10:] if self.processing_steps else []
        
        # é”™è¯¯è®°å½•ï¼ˆå¦‚æœæœ‰ï¼‰
        if self.error_records:
            result["errors"] = self.error_records[-5:]  # æœ€è¿‘5ä¸ªé”™è¯¯
        
        # æ·»åŠ å½“å‰æ—¶ç‚¹å¯ç”¨çš„èµ„é‡‘æ± ä¿¡æ¯
        if hasattr(self.tracker, '_æŠ•èµ„äº§å“èµ„é‡‘æ± ') and self.tracker._æŠ•èµ„äº§å“èµ„é‡‘æ± :
            available_pools = []
            for pool_name, pool_info in self.tracker._æŠ•èµ„äº§å“èµ„é‡‘æ± .items():
                if pool_info.get('æ€»é‡‘é¢', 0) != 0:  # åªæ˜¾ç¤ºæœ‰ä½™é¢çš„èµ„é‡‘æ± 
                    available_pools.append({
                        'name': pool_name,
                        'total_amount': pool_info.get('æ€»é‡‘é¢', 0),
                        'personal_ratio': pool_info.get('ä¸ªäººå æ¯”', 0),
                        'company_ratio': pool_info.get('å…¬å¸å æ¯”', 0)
                    })
            result["available_fund_pools"] = available_pools
        
        return result
    
    def query_fund_pool(self, pool_name: str) -> Dict[str, Any]:
        """
        æŸ¥è¯¢æŒ‡å®šèµ„é‡‘æ± çš„è¯¦ç»†ä¿¡æ¯
        
        Args:
            pool_name: èµ„é‡‘æ± åç§°
            
        Returns:
            èµ„é‡‘æ± æŸ¥è¯¢ç»“æœ
        """
        try:
            if self.tracker is None:
                return {
                    "success": False,
                    "message": "è¿½è¸ªå™¨æœªåˆå§‹åŒ–"
                }
            
            # ç›´æ¥åœ¨è¿™é‡Œå®ç°èµ„é‡‘æ± æŸ¥è¯¢ï¼Œé¿å…å¾ªç¯å¯¼å…¥
            if not hasattr(self.tracker, '_åœºå¤–èµ„é‡‘æ± è®°å½•') or not self.tracker._åœºå¤–èµ„é‡‘æ± è®°å½•:
                return {
                    "success": False,
                    "message": "æ²¡æœ‰æ‰¾åˆ°èµ„é‡‘æ± è®°å½•"
                }
            
            # ç­›é€‰æŒ‡å®šèµ„é‡‘æ± çš„è®°å½•
            pool_records = [
                record for record in self.tracker._åœºå¤–èµ„é‡‘æ± è®°å½•
                if record.get('èµ„é‡‘æ± åç§°') == pool_name
            ]
            
            if not pool_records:
                return {
                    "success": False,
                    "message": f"æ²¡æœ‰æ‰¾åˆ°èµ„é‡‘æ±  {pool_name} çš„è®°å½•"
                }
            
            # å¤„ç†è®°å½•ï¼Œç§»é™¤ä¸éœ€è¦çš„å­—æ®µ
            filtered_records = []
            for record in pool_records:
                filtered_record = {
                    'äº¤æ˜“æ—¶é—´': record.get('äº¤æ˜“æ—¶é—´', ''),
                    'èµ„é‡‘æ± åç§°': record.get('èµ„é‡‘æ± åç§°', ''),
                    'å…¥é‡‘': record.get('å…¥é‡‘', 0),
                    'å‡ºé‡‘': record.get('å‡ºé‡‘', 0),
                    'æ€»ä½™é¢': record.get('æ€»ä½™é¢', 0),
                    'å•ç¬”èµ„é‡‘å æ¯”': record.get('å•ç¬”èµ„é‡‘å æ¯”', record.get('èµ„é‡‘å æ¯”', '')),
                    'æ€»èµ„é‡‘å æ¯”': record.get('æ€»èµ„é‡‘å æ¯”', '')
                    # ä¸åŒ…å«ï¼šè¡Œä¸ºæ€§è´¨ã€ç´¯è®¡ç”³è´­ã€ç´¯è®¡èµå›
                }
                filtered_records.append(filtered_record)
            
            # è®¡ç®—æ±‡æ€»ä¿¡æ¯
            total_inflow = sum(record.get('å…¥é‡‘', 0) for record in pool_records if isinstance(record.get('å…¥é‡‘'), (int, float)))
            total_outflow = sum(record.get('å‡ºé‡‘', 0) for record in pool_records if isinstance(record.get('å‡ºé‡‘'), (int, float)))
            
            # è·å–æœ€æ–°ä½™é¢
            latest_record = pool_records[-1]
            current_balance = latest_record.get('æ€»ä½™é¢', 0)
            
            # æ·»åŠ æ€»è®¡è¡Œ
            summary_record = {
                'äº¤æ˜“æ—¶é—´': 'â”€â”€ æ€»è®¡ â”€â”€',
                'èµ„é‡‘æ± åç§°': f'{pool_name} æ±‡æ€»',
                'å…¥é‡‘': f'æ€»å…¥é‡‘: Â¥{total_inflow:,.0f}',
                'å‡ºé‡‘': f'æ€»å‡ºé‡‘: Â¥{total_outflow:,.0f}',
                'æ€»ä½™é¢': f'å½“å‰ä½™é¢: Â¥{current_balance:,.0f}',
                'å•ç¬”èµ„é‡‘å æ¯”': 'â”€â”€ æ±‡æ€» â”€â”€',
                'æ€»èµ„é‡‘å æ¯”': f'å‡€å˜åŒ–: Â¥{current_balance:,.0f}'
            }
            filtered_records.append(summary_record)
            
            return {
                "success": True,
                "pool_name": pool_name,
                "records": filtered_records,
                "summary": {
                    "total_inflow": total_inflow,
                    "total_outflow": total_outflow,
                    "current_balance": current_balance,
                    "record_count": len(pool_records)
                }
            }
            
        except Exception as e:
            error_msg = f"èµ„é‡‘æ± æŸ¥è¯¢å¤±è´¥: {str(e)}"
            audit_logger.error(error_msg)
            return {
                "success": False,
                "message": error_msg,
                "error_details": str(e)
            }
    
    def _clean_behavior_description(self, behavior: str) -> str:
        """
        æ¸…ç†è¡Œä¸ºæ€§è´¨æè¿°ï¼Œå»æ‰æŠ•èµ„äº§å“çš„å‰ç¼€æ ¼å¼
        
        ä¾‹å¦‚ï¼š
        "ç†è´¢ç”³è´­-ç†è´¢-SYA160401160408ï¼šæŠ•èµ„æŒªç”¨ï¼š1,898,094.23ï¼›ä¸ªäººæŠ•èµ„ï¼š121,905.77"
        â†’ "æŠ•èµ„æŒªç”¨ï¼š1,898,094.23ï¼›ä¸ªäººæŠ•èµ„ï¼š121,905.77"
        
        ä¿æŒéæŠ•èµ„è¡Œä¸ºä¸å˜ï¼š
        "å«ä»˜ï¼š5,766.13ï¼›å…¬å¸æ”¯ä»˜ï¼š533.87" â†’ "å«ä»˜ï¼š5,766.13ï¼›å…¬å¸æ”¯ä»˜ï¼š533.87"
        """
        if not behavior:
            return behavior
        
        # æ£€æŸ¥æ˜¯å¦åŒ…å«æŠ•èµ„äº§å“çš„å‰ç¼€æ ¼å¼ï¼ˆå¦‚ï¼šç†è´¢ç”³è´­-ç†è´¢-SYA160401160408ï¼šï¼‰
        import re
        investment_prefix_pattern = r'^[^ï¼š]*ç”³è´­-[^ï¼š]*ï¼š'
        
        if re.match(investment_prefix_pattern, behavior):
            # å»æ‰å‰ç¼€ï¼Œåªä¿ç•™å†’å·åé¢çš„å†…å®¹
            parts = behavior.split('ï¼š', 1)
            if len(parts) > 1:
                return parts[1]
        
        return behavior
    
    def _save_to_history(self, query_result: Dict[str, Any]) -> None:
        """
        ä¿å­˜æŸ¥è¯¢ç»“æœåˆ°å†å²è®°å½•
        
        Args:
            query_result: æŸ¥è¯¢ç»“æœ
        """
        # ç®€åŒ–å†å²è®°å½•ï¼ˆåªä¿å­˜å…³é”®ä¿¡æ¯ï¼‰
        history_item = {
            "id": len(self.query_history) + 1,
            "algorithm": query_result["algorithm"],
            "target_row": query_result["target_row"],
            "query_time": query_result["query_time"],
            "processing_time": query_result["processing_time"],
            "success": query_result["success"],
            "tracker_state": query_result.get("tracker_state", {}),
            "error_count": query_result.get("processing_stats", {}).get("error_count", 0)
        }
        
        self.query_history.append(history_item)
        
        # ä¿æŒå†å²è®°å½•ä¸è¶…è¿‡æœ€å¤§é•¿åº¦
        if len(self.query_history) > self.MAX_HISTORY_SIZE:
            self.query_history = self.query_history[-self.MAX_HISTORY_SIZE:]
    
    def get_query_history(self, limit: int = 20) -> List[Dict[str, Any]]:
        """
        è·å–æŸ¥è¯¢å†å²è®°å½•
        
        Args:
            limit: è¿”å›è®°å½•æ•°é‡é™åˆ¶
            
        Returns:
            å†å²è®°å½•åˆ—è¡¨ï¼ˆæœ€æ–°çš„åœ¨å‰ï¼‰
        """
        return self.query_history[-limit:][::-1]
    
    def clear_history(self) -> Dict[str, Any]:
        """
        æ¸…é™¤æŸ¥è¯¢å†å²è®°å½•
        
        Returns:
            æ¸…é™¤ç»“æœ
        """
        cleared_count = len(self.query_history)
        self.query_history.clear()
        
        return {
            "success": True,
            "message": f"å·²æ¸…é™¤ {cleared_count} æ¡å†å²è®°å½•"
        }
    
    def export_query_result(self, query_result: Dict[str, Any], file_path: str) -> Dict[str, Any]:
        """
        å¯¼å‡ºæŸ¥è¯¢ç»“æœåˆ°æ–‡ä»¶
        
        Args:
            query_result: æŸ¥è¯¢ç»“æœ
            file_path: å¯¼å‡ºæ–‡ä»¶è·¯å¾„
            
        Returns:
            å¯¼å‡ºç»“æœ
        """
        try:
            if file_path.endswith('.json'):
                # å¯¼å‡ºä¸ºJSON
                with open(file_path, 'w', encoding='utf-8') as f:
                    json.dump(query_result, f, ensure_ascii=False, indent=2, default=str)
                    
            elif file_path.endswith('.xlsx'):
                # å¯¼å‡ºä¸ºExcel
                self._export_to_excel(query_result, file_path)
                
            else:
                return {
                    "success": False,
                    "message": "ä¸æ”¯æŒçš„æ–‡ä»¶æ ¼å¼ï¼Œè¯·ä½¿ç”¨ .json æˆ– .xlsx"
                }
            
            audit_logger.info(f"æŸ¥è¯¢ç»“æœå·²å¯¼å‡ºè‡³: {file_path}")
            return {
                "success": True,
                "message": f"æŸ¥è¯¢ç»“æœå·²å¯¼å‡ºè‡³: {file_path}",
                "file_path": file_path
            }
            
        except Exception as e:
            error_msg = f"å¯¼å‡ºå¤±è´¥: {str(e)}"
            audit_logger.error(error_msg)
            return {
                "success": False,
                "message": error_msg,
                "error_details": str(e)
            }
    
    def _export_to_excel(self, query_result: Dict[str, Any], file_path: str) -> None:
        """
        å¯¼å‡ºæŸ¥è¯¢ç»“æœåˆ°Excelæ–‡ä»¶
        
        Args:
            query_result: æŸ¥è¯¢ç»“æœ
            file_path: Excelæ–‡ä»¶è·¯å¾„
        """
        import pandas as pd
        
        with pd.ExcelWriter(file_path, engine='openpyxl') as writer:
            # åŸºæœ¬ä¿¡æ¯
            basic_info = pd.DataFrame([{
                "ç®—æ³•": query_result.get("algorithm"),
                "ç›®æ ‡è¡Œæ•°": query_result.get("target_row"),
                "æŸ¥è¯¢æ—¶é—´": query_result.get("query_time"),
                "å¤„ç†æ—¶é—´(ç§’)": query_result.get("processing_time"),
                "æ•°æ®æ€»è¡Œæ•°": query_result.get("total_rows")
            }])
            basic_info.to_excel(writer, sheet_name='åŸºæœ¬ä¿¡æ¯', index=False)
            
            # è¿½è¸ªå™¨çŠ¶æ€
            if "tracker_state" in query_result:
                state = query_result["tracker_state"]
                tracker_info = pd.DataFrame([{
                    "ä¸ªäººä½™é¢": state.get("personal_balance", 0),
                    "å…¬å¸ä½™é¢": state.get("company_balance", 0),
                    "æ€»ä½™é¢": state.get("total_balance", 0),
                    "ç´¯è®¡æŒªç”¨": state.get("total_misuse", 0),
                    "ç´¯è®¡å«ä»˜": state.get("total_advance", 0),
                    "å·²å½’è¿˜å…¬å¸æœ¬é‡‘": state.get("total_returned_company", 0),
                    "å·²å½’è¿˜ä¸ªäººæœ¬é‡‘": state.get("total_returned_personal", 0),
                    "ä¸ªäººåˆ©æ¶¦": state.get("personal_profit", 0),
                    "å…¬å¸åˆ©æ¶¦": state.get("company_profit", 0)
                }])
                tracker_info.to_excel(writer, sheet_name='è¿½è¸ªå™¨çŠ¶æ€', index=False)
            
            # ç›®æ ‡è¡Œæ•°æ®
            if "target_row_data" in query_result:
                row_data = query_result["target_row_data"]
                target_info = pd.DataFrame([row_data])
                target_info.to_excel(writer, sheet_name='ç›®æ ‡è¡Œæ•°æ®', index=False)
            
            # å¤„ç†æ­¥éª¤ï¼ˆå¦‚æœæœ‰ï¼‰
            if "recent_steps" in query_result and query_result["recent_steps"]:
                steps_df = pd.DataFrame(query_result["recent_steps"])
                steps_df.to_excel(writer, sheet_name='å¤„ç†æ­¥éª¤', index=False)
            
            # é”™è¯¯è®°å½•ï¼ˆå¦‚æœæœ‰ï¼‰
            if "errors" in query_result and query_result["errors"]:
                errors_df = pd.DataFrame(query_result["errors"])
                errors_df.to_excel(writer, sheet_name='é”™è¯¯è®°å½•', index=False)
    
    def get_service_status(self) -> Dict[str, Any]:
        """
        è·å–æœåŠ¡çŠ¶æ€ä¿¡æ¯
        
        Returns:
            æœåŠ¡çŠ¶æ€
        """
        return {
            "algorithm": self.algorithm,
            "data_loaded": self.data is not None,
            "total_rows": self.total_rows,
            "current_row": self.current_row,
            "history_count": len(self.query_history),
            "max_history_size": self.MAX_HISTORY_SIZE,
            "tracker_initialized": self.tracker is not None and self.tracker.å·²åˆå§‹åŒ– if self.tracker else False
        }